{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import os\n"
      ],
      "metadata": {
        "id": "J_mdgJ-9vF0-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7voAE4dfu7kS",
        "outputId": "b0e89f60-1cd2-41da-b9cc-1a6ec7f66d07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ShallowWaterJAX'...\n",
            "remote: Enumerating objects: 32, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 32 (delta 8), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (32/32), 8.58 MiB | 7.32 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/anthony-frion/ShallowWaterJAX"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_checkpoint(filename='my_checkpoint.pth.tar', device='cpu'):\n",
        "  # with torch.no_grad():\n",
        "    assert os.path.isfile(filename), f\"Error: {filename} not found\"\n",
        "    if os.path.isfile(filename):\n",
        "        checkpoint = torch.load(filename, map_location=torch.device(device), weights_only=True)\n",
        "        return checkpoint"
      ],
      "metadata": {
        "id": "Jf6ypLBVwgkU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ShallowWaterJAX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "temv-rO9xF_t",
        "outputId": "69d3272d-4ae4-4ff9-c25c-30adfe589e7f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ShallowWaterJAX\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwCLC9MGxb-j",
        "outputId": "b2fadc0e-7e99-49a1-ecf7-4a7e58d8b94f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4DVar.ipynb  model.pth.tar  pytorch_assimilation.py\tpytorch_model.py\tpytorch_swe_inv.py\n",
            "data.pkl     project.md     pytorch_emulator_module.py\tpytorch_observation.py\tREADME.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_model import UNET2D"
      ],
      "metadata": {
        "id": "goxi6Jv5wwuW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = get_checkpoint(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ioaxm3Xjwj48",
        "outputId": "dae035c9-a488-4851-c861-8f4c73791dbe"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['dynamics.weight', 'dynamics.bias', 'statics.weight', 'statics.bias', 'encoder.0.conv.0.weight', 'encoder.0.conv.0.bias', 'encoder.0.conv.1.weight', 'encoder.0.conv.1.bias', 'encoder.0.conv.3.weight', 'encoder.0.conv.3.bias', 'encoder.0.conv.4.weight', 'encoder.0.conv.4.bias', 'encoder.1.conv.0.weight', 'encoder.1.conv.0.bias', 'encoder.1.conv.1.weight', 'encoder.1.conv.1.bias', 'encoder.1.conv.3.weight', 'encoder.1.conv.3.bias', 'encoder.1.conv.4.weight', 'encoder.1.conv.4.bias', 'encoder.2.conv.0.weight', 'encoder.2.conv.0.bias', 'encoder.2.conv.1.weight', 'encoder.2.conv.1.bias', 'encoder.2.conv.3.weight', 'encoder.2.conv.3.bias', 'encoder.2.conv.4.weight', 'encoder.2.conv.4.bias', 'encoder.3.conv.0.weight', 'encoder.3.conv.0.bias', 'encoder.3.conv.1.weight', 'encoder.3.conv.1.bias', 'encoder.3.conv.3.weight', 'encoder.3.conv.3.bias', 'encoder.3.conv.4.weight', 'encoder.3.conv.4.bias', 'encoder.4.conv.0.weight', 'encoder.4.conv.0.bias', 'encoder.4.conv.1.weight', 'encoder.4.conv.1.bias', 'encoder.4.conv.3.weight', 'encoder.4.conv.3.bias', 'encoder.4.conv.4.weight', 'encoder.4.conv.4.bias', 'up.0.weight', 'up.0.bias', 'up.1.weight', 'up.1.bias', 'up.2.weight', 'up.2.bias', 'up.3.weight', 'up.3.bias', 'decoder.0.conv.0.weight', 'decoder.0.conv.0.bias', 'decoder.0.conv.1.weight', 'decoder.0.conv.1.bias', 'decoder.0.conv.3.weight', 'decoder.0.conv.3.bias', 'decoder.0.conv.4.weight', 'decoder.0.conv.4.bias', 'decoder.1.conv.0.weight', 'decoder.1.conv.0.bias', 'decoder.1.conv.1.weight', 'decoder.1.conv.1.bias', 'decoder.1.conv.3.weight', 'decoder.1.conv.3.bias', 'decoder.1.conv.4.weight', 'decoder.1.conv.4.bias', 'decoder.2.conv.0.weight', 'decoder.2.conv.0.bias', 'decoder.2.conv.1.weight', 'decoder.2.conv.1.bias', 'decoder.2.conv.3.weight', 'decoder.2.conv.3.bias', 'decoder.2.conv.4.weight', 'decoder.2.conv.4.bias', 'decoder.3.conv.0.weight', 'decoder.3.conv.0.bias', 'decoder.3.conv.1.weight', 'decoder.3.conv.1.bias', 'decoder.3.conv.3.weight', 'decoder.3.conv.3.bias', 'decoder.3.conv.4.weight', 'decoder.3.conv.4.bias', 'output.weight', 'output.bias']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys = [x for x in checkpoint['model_state_dict']]\n",
        "print(keys) # See the keys of all tensors stored in there\n",
        "for key in keys:\n",
        "  print(key, checkpoint['model_state_dict'][key].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S52yXlJy0x44",
        "outputId": "22470521-088a-4fb3-8007-ff11b5fbfec7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['dynamics.weight', 'dynamics.bias', 'statics.weight', 'statics.bias', 'encoder.0.conv.0.weight', 'encoder.0.conv.0.bias', 'encoder.0.conv.1.weight', 'encoder.0.conv.1.bias', 'encoder.0.conv.3.weight', 'encoder.0.conv.3.bias', 'encoder.0.conv.4.weight', 'encoder.0.conv.4.bias', 'encoder.1.conv.0.weight', 'encoder.1.conv.0.bias', 'encoder.1.conv.1.weight', 'encoder.1.conv.1.bias', 'encoder.1.conv.3.weight', 'encoder.1.conv.3.bias', 'encoder.1.conv.4.weight', 'encoder.1.conv.4.bias', 'encoder.2.conv.0.weight', 'encoder.2.conv.0.bias', 'encoder.2.conv.1.weight', 'encoder.2.conv.1.bias', 'encoder.2.conv.3.weight', 'encoder.2.conv.3.bias', 'encoder.2.conv.4.weight', 'encoder.2.conv.4.bias', 'encoder.3.conv.0.weight', 'encoder.3.conv.0.bias', 'encoder.3.conv.1.weight', 'encoder.3.conv.1.bias', 'encoder.3.conv.3.weight', 'encoder.3.conv.3.bias', 'encoder.3.conv.4.weight', 'encoder.3.conv.4.bias', 'encoder.4.conv.0.weight', 'encoder.4.conv.0.bias', 'encoder.4.conv.1.weight', 'encoder.4.conv.1.bias', 'encoder.4.conv.3.weight', 'encoder.4.conv.3.bias', 'encoder.4.conv.4.weight', 'encoder.4.conv.4.bias', 'up.0.weight', 'up.0.bias', 'up.1.weight', 'up.1.bias', 'up.2.weight', 'up.2.bias', 'up.3.weight', 'up.3.bias', 'decoder.0.conv.0.weight', 'decoder.0.conv.0.bias', 'decoder.0.conv.1.weight', 'decoder.0.conv.1.bias', 'decoder.0.conv.3.weight', 'decoder.0.conv.3.bias', 'decoder.0.conv.4.weight', 'decoder.0.conv.4.bias', 'decoder.1.conv.0.weight', 'decoder.1.conv.0.bias', 'decoder.1.conv.1.weight', 'decoder.1.conv.1.bias', 'decoder.1.conv.3.weight', 'decoder.1.conv.3.bias', 'decoder.1.conv.4.weight', 'decoder.1.conv.4.bias', 'decoder.2.conv.0.weight', 'decoder.2.conv.0.bias', 'decoder.2.conv.1.weight', 'decoder.2.conv.1.bias', 'decoder.2.conv.3.weight', 'decoder.2.conv.3.bias', 'decoder.2.conv.4.weight', 'decoder.2.conv.4.bias', 'decoder.3.conv.0.weight', 'decoder.3.conv.0.bias', 'decoder.3.conv.1.weight', 'decoder.3.conv.1.bias', 'decoder.3.conv.3.weight', 'decoder.3.conv.3.bias', 'decoder.3.conv.4.weight', 'decoder.3.conv.4.bias', 'output.weight', 'output.bias']\n",
            "dynamics.weight torch.Size([8, 3, 3, 3])\n",
            "dynamics.bias torch.Size([8])\n",
            "statics.weight torch.Size([8, 2, 3, 3])\n",
            "statics.bias torch.Size([8])\n",
            "encoder.0.conv.0.weight torch.Size([16, 16, 3, 3])\n",
            "encoder.0.conv.0.bias torch.Size([16])\n",
            "encoder.0.conv.1.weight torch.Size([16])\n",
            "encoder.0.conv.1.bias torch.Size([16])\n",
            "encoder.0.conv.3.weight torch.Size([16, 16, 3, 3])\n",
            "encoder.0.conv.3.bias torch.Size([16])\n",
            "encoder.0.conv.4.weight torch.Size([16])\n",
            "encoder.0.conv.4.bias torch.Size([16])\n",
            "encoder.1.conv.0.weight torch.Size([32, 16, 3, 3])\n",
            "encoder.1.conv.0.bias torch.Size([32])\n",
            "encoder.1.conv.1.weight torch.Size([32])\n",
            "encoder.1.conv.1.bias torch.Size([32])\n",
            "encoder.1.conv.3.weight torch.Size([32, 32, 3, 3])\n",
            "encoder.1.conv.3.bias torch.Size([32])\n",
            "encoder.1.conv.4.weight torch.Size([32])\n",
            "encoder.1.conv.4.bias torch.Size([32])\n",
            "encoder.2.conv.0.weight torch.Size([64, 32, 3, 3])\n",
            "encoder.2.conv.0.bias torch.Size([64])\n",
            "encoder.2.conv.1.weight torch.Size([64])\n",
            "encoder.2.conv.1.bias torch.Size([64])\n",
            "encoder.2.conv.3.weight torch.Size([64, 64, 3, 3])\n",
            "encoder.2.conv.3.bias torch.Size([64])\n",
            "encoder.2.conv.4.weight torch.Size([64])\n",
            "encoder.2.conv.4.bias torch.Size([64])\n",
            "encoder.3.conv.0.weight torch.Size([128, 64, 3, 3])\n",
            "encoder.3.conv.0.bias torch.Size([128])\n",
            "encoder.3.conv.1.weight torch.Size([128])\n",
            "encoder.3.conv.1.bias torch.Size([128])\n",
            "encoder.3.conv.3.weight torch.Size([128, 128, 3, 3])\n",
            "encoder.3.conv.3.bias torch.Size([128])\n",
            "encoder.3.conv.4.weight torch.Size([128])\n",
            "encoder.3.conv.4.bias torch.Size([128])\n",
            "encoder.4.conv.0.weight torch.Size([256, 128, 3, 3])\n",
            "encoder.4.conv.0.bias torch.Size([256])\n",
            "encoder.4.conv.1.weight torch.Size([256])\n",
            "encoder.4.conv.1.bias torch.Size([256])\n",
            "encoder.4.conv.3.weight torch.Size([256, 256, 3, 3])\n",
            "encoder.4.conv.3.bias torch.Size([256])\n",
            "encoder.4.conv.4.weight torch.Size([256])\n",
            "encoder.4.conv.4.bias torch.Size([256])\n",
            "up.0.weight torch.Size([256, 128, 2, 2])\n",
            "up.0.bias torch.Size([128])\n",
            "up.1.weight torch.Size([128, 64, 2, 2])\n",
            "up.1.bias torch.Size([64])\n",
            "up.2.weight torch.Size([64, 32, 2, 2])\n",
            "up.2.bias torch.Size([32])\n",
            "up.3.weight torch.Size([32, 16, 2, 2])\n",
            "up.3.bias torch.Size([16])\n",
            "decoder.0.conv.0.weight torch.Size([128, 256, 3, 3])\n",
            "decoder.0.conv.0.bias torch.Size([128])\n",
            "decoder.0.conv.1.weight torch.Size([128])\n",
            "decoder.0.conv.1.bias torch.Size([128])\n",
            "decoder.0.conv.3.weight torch.Size([128, 128, 3, 3])\n",
            "decoder.0.conv.3.bias torch.Size([128])\n",
            "decoder.0.conv.4.weight torch.Size([128])\n",
            "decoder.0.conv.4.bias torch.Size([128])\n",
            "decoder.1.conv.0.weight torch.Size([64, 128, 3, 3])\n",
            "decoder.1.conv.0.bias torch.Size([64])\n",
            "decoder.1.conv.1.weight torch.Size([64])\n",
            "decoder.1.conv.1.bias torch.Size([64])\n",
            "decoder.1.conv.3.weight torch.Size([64, 64, 3, 3])\n",
            "decoder.1.conv.3.bias torch.Size([64])\n",
            "decoder.1.conv.4.weight torch.Size([64])\n",
            "decoder.1.conv.4.bias torch.Size([64])\n",
            "decoder.2.conv.0.weight torch.Size([32, 64, 3, 3])\n",
            "decoder.2.conv.0.bias torch.Size([32])\n",
            "decoder.2.conv.1.weight torch.Size([32])\n",
            "decoder.2.conv.1.bias torch.Size([32])\n",
            "decoder.2.conv.3.weight torch.Size([32, 32, 3, 3])\n",
            "decoder.2.conv.3.bias torch.Size([32])\n",
            "decoder.2.conv.4.weight torch.Size([32])\n",
            "decoder.2.conv.4.bias torch.Size([32])\n",
            "decoder.3.conv.0.weight torch.Size([16, 32, 3, 3])\n",
            "decoder.3.conv.0.bias torch.Size([16])\n",
            "decoder.3.conv.1.weight torch.Size([16])\n",
            "decoder.3.conv.1.bias torch.Size([16])\n",
            "decoder.3.conv.3.weight torch.Size([16, 16, 3, 3])\n",
            "decoder.3.conv.3.bias torch.Size([16])\n",
            "decoder.3.conv.4.weight torch.Size([16])\n",
            "decoder.3.conv.4.bias torch.Size([16])\n",
            "output.weight torch.Size([3, 16, 3, 3])\n",
            "output.bias torch.Size([3])\n"
          ]
        }
      ]
    }
  ]
}